# -*- coding: utf-8 -*-
"""web_app.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1p4_vMTsa8r2vHg67UJQxT6GQ9zOVh1ON
"""

import streamlit as st
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.neighbors import KNeighborsClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC
from sklearn.metrics import classification_report, confusion_matrix
from sklearn.preprocessing import LabelEncoder
from sklearn.impute import SimpleImputer

# Configure Streamlit
st.title("Data Cleaning and Machine Learning App")

# File upload
uploaded_file = st.sidebar.file_uploader("Upload your dataset (CSV only)", type="csv")

if uploaded_file:
    # Load the dataset
    dataset = pd.read_csv(uploaded_file)
    st.write("### Original Dataset")
    st.dataframe(dataset.head())
    st.write(f"Dataset Shape: {dataset.shape}")

    # Data Cleaning
    st.sidebar.subheader("Data Cleaning Options")
    if st.sidebar.checkbox("Remove duplicate rows"):
        dataset = dataset.drop_duplicates()
        st.write("### After Removing Duplicate Rows")
        st.dataframe(dataset.head())
        st.write(f"Dataset Shape: {dataset.shape}")

    if st.sidebar.checkbox("Remove null values"):
        target_column = st.sidebar.selectbox("Select Target Column for Null Value Removal", dataset.columns)
        dataset = dataset.dropna(subset=[target_column])
        st.write("### After Removing Null Values")
        st.dataframe(dataset.head())
        st.write(f"Dataset Shape: {dataset.shape}")
        st.write("Null values per column:")
        st.write(dataset.isnull().sum())

    if st.sidebar.checkbox("Clean string data"):
        if "Gender" in dataset.columns:
            dataset['Gender'] = dataset['Gender'].replace(
                {'Male': 'male', 'M': 'male', 'Female': 'female', 'F': 'female'})
        columns_to_lowercase = [col for col in ['Customer Type', 'Type Of Travel', 'Class'] if col in dataset.columns]
        if columns_to_lowercase:
            dataset[columns_to_lowercase] = dataset[columns_to_lowercase].apply(lambda x: x.str.lower())
        st.write("### After Cleaning String Data")
        st.dataframe(dataset.head())

    if st.sidebar.checkbox("Correct data types"):
        if "Departure Delay In Minutes" in dataset.columns:
            dataset = dataset[dataset['Departure Delay In Minutes'].apply(lambda x: str(x).isdigit())]
            dataset['Departure Delay In Minutes'] = dataset['Departure Delay In Minutes'].astype(float)
            st.write("### After Correcting Data Types")
            st.dataframe(dataset.head())
            st.write(f"Datatype of 'Departure Delay In Minutes': {dataset['Departure Delay In Minutes'].dtype}")

    # Machine Learning
    st.sidebar.subheader("Machine Learning Options")
    target_column = st.sidebar.selectbox("Select Target Column", dataset.columns)
    model_type = st.sidebar.radio("Select Model Type", ["Logistic Regression", "KNN", "Random Forest", "SVM"])

    if target_column and st.sidebar.button("Train Model"):
        # Preprocessing and splitting the dataset
        X = dataset.drop(target_column, axis=1)
        y = dataset[target_column]

        # Convert non-numeric columns in X to dummy variables
        X = pd.get_dummies(X, drop_first=True)

        # Encode target variable
        le = LabelEncoder()
        y = le.fit_transform(y)

        # Handle missing values in X
        imputer = SimpleImputer(strategy="mean")  # Replace missing values with column mean
        X = imputer.fit_transform(X)

        # Split the dataset
        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

        # Train the selected model
        if model_type == "Logistic Regression":
            model = LogisticRegression(max_iter=1000)
        elif model_type == "KNN":
            model = KNeighborsClassifier(n_neighbors=5)
        elif model_type == "Random Forest":
            model = RandomForestClassifier(n_estimators=100, random_state=42)
        elif model_type == "SVM":
            model = SVC(kernel="linear")

        model.fit(X_train, y_train)
        y_pred = model.predict(X_test)

        # Display Metrics
        st.write("### Classification Report")
        st.text(classification_report(y_test, y_pred))

        # Visualization
        st.write("### Confusion Matrix")
        cm = confusion_matrix(y_test, y_pred)
        sns.heatmap(cm, annot=True, fmt="d", cmap="Blues")
        st.pyplot(plt)

        # Feature Importance for Random Forest
        if model_type == "Random Forest":
            importances = model.feature_importances_
            st.write("### Feature Importances")
            plt.figure(figsize=(10, 6))
            sns.barplot(x=np.arange(len(importances)), y=importances, palette="coolwarm")
            plt.title("Feature Importances")
            st.pyplot(plt)


